## TL;DR
I am exploring the concept of using ChatGPT to ghost-write prose from my point-form notes.  

I am using ChatGPT to convert my point-form notes into an essay for a blog or as a subsection for a book.
## Overview
1. I created a brainstorm in Kinopio about a single topic, containing only 7 point-form notes.
2. I re-typed the brainstorm in markdown format into a .md file.
3. I fed the .md file to ChatGPT and received a response that looks reasonable.

### Background
I believe that there should be a distinction between the concepts of *data* and *control flow*.  Control flow is the *interpretation* of *data*.  *Data*, itself is static.  A CPU *interprets* data - opcodes.

I am struggling, trying to find the right words to explain this distinction.

I like to write in point-form.  

I believe that an *idea* is more important than a particular realization of that idea.  

I believe in the concept of *showing your work*.  To this end, I publish *ideas* and show the *experiments* that support the ideas.  Typically, very little of my code is directly usable, except, maybe, by someone who is inspired by the idea and wants to further riff on the idea.

I tend not to go back and edit my point-form notes.  In essence, I want "someone" to re-cast my notes into prose.  In the past, one would employ editors and ghost-writers.  I am exploring the concept of using ChatGPT to ghost-write prose from my notes.  

Thus far, the indications are positive.  ChatGPT ingests my 7-point note - in markdown format - and generates reasonable prose, suitable to use a subsection of a chapter in a book, or, as an essay on a blog.

## Future 1
I am building a pipeline - in drawware/0D - to take raw JSON exported from Kinopio and to  convert it to point-form notes in markdown format.

The pipeline uses JavaScript, Python, PROLOG (SWIPL), draw.io, OhmJS, RWR, and, odin0d.

Thus far, the pipeline converts JSON from Kinopio into a PROLOG factbase.  I manually copy/paste the factbase into a PROLOG program `md.pl` and then run the program using the commands:
```
swipl
consult(md).
main.
```

The next step will be modifying the `main` diagram in `top.drawio` to glue the generated factbase and `md.pl` together, then, shelling-out to SWIPL to generate the markdown point-form text.

## Future 2
I am playing with `Khoj` to see if I can AI-generate reasonable responses on my local machine without moving my data off of my local machine.

This certainly seems to generate prose more slowly (tens of minutes, instead of seconds) than ChatGPT, but, holds some promise.
## Code Repo

[kinopio2md](https://github.com/guitarvydas/kinopio2md)

This is a stand-alone repo that contains all of `odin0d` and `top.drawio` (the diagram of my pipeline).

## How Does This All Fit In With My Other Projects?
- RT
- odin0d
- find-and-replace
- transpiler
- OhmJS
- Ceptre
- Software Atoms
- Behavior Trees
- Blogging and Book Writing
- Code Commenting
	- describe operation of code
	- describe Architecture
- Operators and Operands
- Golf
	- Flow
		- "Analysis Paralysis"
- Something is Rotten in Denmark
- Software Simplicity
## BRAINSTORMING:
I Use Kinopio to capture ideas in point form:
![control flow is not data](/screenshots/Screenshot 2023-10-30 at 4.31.58 AM.png)

## Interacting With My Ghost Writer ChatGPT 

I paste text into ChatGPT's chat window.  The sections labelled "PROMPT:" are what I typed in.  The sections labelled "REPONSE:" are responses generated by ChatGPT.
### PROMPT: 
summarize the following markdown as a subsection for a chapter in a book

### RESPONSE: 

I'd be happy to help you summarize the content, but it seems like you haven't provided the specific Markdown content you'd like me to summarize. Please paste the content you want summarized, and I'll assist you in creating a subsection for a chapter in a book based on that content.

### PROMPT:
*[I manually created this file, using the above Kinopio brainstorm as a guide]*

control flow is not data
- control flow is _interpretation_ of data - dynamic flow
    - a CPU is an interpreter
        - a CPU interprets _opcodes_
        - a CPU interprets _opcodes_ so quickly that we think of it as something other than interpretation
- data is _static_ - and is not interpreted by the underlying system
    - static data is interpreted by the _program_, not the CPU

### REPONSE:
**Chapter Subsection: Control Flow and Data Interpretation**

In this subsection, we explore the fundamental distinction between control flow and data in the context of computing. 

**Control Flow Is Not Data**

Control flow is a crucial aspect of computational systems, but it differs significantly from data. Control flow involves the dynamic interpretation of data to direct the execution of a program. In essence, it is the decision-making process that determines which steps the computer should take next.

**Control Flow as Interpretation of Data**

Control flow can be best understood as the interpretation of data, giving rise to a dynamic flow of instructions. Much like a conductor guiding an orchestra, the Central Processing Unit (CPU) is the interpreter of these instructions in a computer system.

- **The CPU as an Interpreter:** A CPU serves as the chief interpreter in a computing system. It deciphers and executes the low-level instructions known as opcodes. These opcodes are the elemental commands that drive the CPU's operations.

- **Swift Interpretation:** CPUs interpret opcodes so rapidly that it often appears as if they are not interpreting at all. This blistering speed can lead us to perceive the CPU's actions as something other than interpretation, concealing the underlying intricacies of control flow.

**Data Is Static and Program-Interpreted**

In contrast to control flow, data is inherently static and is not directly interpreted by the underlying hardware. Instead, data interpretation is primarily carried out by the software program itself.

- **Static Nature of Data:** Data remains relatively unchanging and does not actively participate in the dynamic decision-making processes that control flow orchestrates.

- **Program-Driven Data Interpretation:** It is the responsibility of the software program to interpret and manipulate data. The program determines how data is accessed, processed, and used, bringing a level of predictability and consistency to the handling of information.

Understanding this distinction between control flow and data is fundamental in the realm of computer science, as it lays the groundwork for comprehending how computers execute instructions and manage data effectively.

## See Also
### Blogs
[blog](https://guitarvydas.github.io/)

[obsidian blogs](https://publish.obsidian.md/programmingsimplicity) (see blogs that begin with a date 202x-xx-xx-)
### Videos
[videos - programming simplicity playlist](https://www.youtube.com/@programmingsimplicity2980)
### Books
leanpub'ed (disclaimer: leanpub encourages publishing books before they are finalized - these books are WIPs)
[Programming Simplicity Takeaways, and, Programming Simplicity Broad Brush](https://leanpub.com/u/paul-tarvydas)
### Discord
[Programming Simplicity](https://discord.gg/Jjx62ypR) all welcome, I invite more discussion of these topics, esp. regarding Drawware and 0D
### Twitter
@paul_tarvydas
### Mastodon
(tbd, advice needed re. most appropriate server(s))

<script src="https://utteranc.es/client.js" 
        repo="guitarvydas/guitarvydas.github.io" 
        issue-term="pathname" 
        theme="github-light" 
        crossorigin="anonymous" 
        async> 
</script> 
